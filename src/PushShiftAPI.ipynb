{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60d52869",
   "metadata": {},
   "source": [
    "# This is a PushShiftAPI exploration file. \n",
    "\n",
    "## In here, you can pull data from PushshiftAPI and save it as CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06e1b320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psaw import PushshiftAPI\n",
    "import pandas as pd\n",
    "\n",
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2fe4d0",
   "metadata": {},
   "source": [
    "## PushShiftAPI sanity test\n",
    "\n",
    "This sanity tests scrapes the newest post on PushShiftAPI. Changes every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3afde37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission(author='WarnersBrosCA', created_utc=1644797487, subreddit='u_WarnersBrosCA', title='Is it a signal or a warning? Watch #TheBatman, In Theatres March 4.', url='https://ad.doubleclick.net/ddm/trackclk/N7217.131843.REDDIT.COM/B27153524.327036345;dc_trk_aid=519508530;dc_trk_cid=165617380;dc_lat=;dc_rdid={{ADVERTISING_ID}};tag_for_child_directed_treatment=;tfua=;ltd=', created=1644815487.0, d_={'author': 'WarnersBrosCA', 'created_utc': 1644797487, 'subreddit': 'u_WarnersBrosCA', 'title': 'Is it a signal or a warning? Watch #TheBatman, In Theatres March 4.', 'url': 'https://ad.doubleclick.net/ddm/trackclk/N7217.131843.REDDIT.COM/B27153524.327036345;dc_trk_aid=519508530;dc_trk_cid=165617380;dc_lat=;dc_rdid={{ADVERTISING_ID}};tag_for_child_directed_treatment=;tfua=;ltd=', 'created': 1644815487.0})\n",
      "happened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/albertlu/opt/anaconda3/envs/Antiwork/lib/python3.10/site-packages/psaw/PushshiftAPI.py:252: UserWarning: Not all PushShift shards are active. Query results may be incomplete\n",
      "  warnings.warn(shards_down_message)\n"
     ]
    }
   ],
   "source": [
    "gen = api.search_submissions(filter=['url','author', 'title', 'subreddit'], limit=1)\n",
    "for post in gen:\n",
    "    print(post)\n",
    "print(\"happened\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e866c9c",
   "metadata": {},
   "source": [
    "## Helper function that takes in a dataset & columns and saves as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14c8600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_csv(data, cols, label):\n",
    "    df = pd.DataFrame(data, columns=cols)\n",
    "    df.to_csv(label + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe161bf3",
   "metadata": {},
   "source": [
    "# Main scraping function\n",
    "\n",
    "## The function below scrapes all submission IDs & timestamps from r/antiwork from 2014-2021 and saves it as CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c710e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "def scrape_everything():\n",
    "    all_ids = []\n",
    "    params = ['id', 'created_utc']\n",
    "    for year in range(2014, 2022):\n",
    "        year = str(year)\n",
    "        for month in range(1, 13):\n",
    "            monthly_ids = []\n",
    "            month = str(month)\n",
    "            label = year + \"-\" + month\n",
    "            if month == '12':\n",
    "                start_epoch = int(datetime(int(year), int(month), 1).timestamp())\n",
    "                end_epoch = int(datetime(int(year) + 1, 1, 1).timestamp())\n",
    "            else:\n",
    "                start_epoch = int(datetime(int(year), int(month), 1).timestamp())\n",
    "                end_epoch = int(datetime(int(year), int(month) + 1, 1).timestamp())\n",
    "            gen = api.search_submissions(after=start_epoch,\n",
    "                                         before = end_epoch,\n",
    "                                        subreddit='antiwork',\n",
    "                                        filter=params,\n",
    "                                        limit=None)\n",
    "            for post in tqdm(gen):\n",
    "                all_ids.append([post.id, post.created_utc])\n",
    "                monthly_ids.append([post.id, post.created_utc])\n",
    "            save_as_csv(monthly_ids, params, label)\n",
    "            print(\"Got through \" + year + \"-\" + month)\n",
    "    save_as_csv(all_ids, params, \"all_ids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd21b59",
   "metadata": {},
   "source": [
    "## This function merges two csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf04a5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.getcwd()\n",
    "def merge_csv(csv1, csv2, name):\n",
    "    a = pd.read_csv(csv1, index_col = 0)\n",
    "    b = pd.read_csv(csv2, index_col = 0)\n",
    "\n",
    "    merged = pd.concat([a, b], axis = 0, ignore_index = True)\n",
    "    merged.to_csv(name + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aebbfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
