{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a list of unique users with their activity statistics\n",
    "\n",
    "This notebook scans through all collected user activity files and produces user-level statistics:\n",
    " - number of posts\n",
    " - number of comments\n",
    " - total post karma\n",
    " - total comment karma\n",
    " - first and last date\n",
    "\n",
    "The data produced is stored in a SQLite database under `/data/users/` (table users) and used for many downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import time\n",
    "import sqlite3\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files to process: 489\n"
     ]
    }
   ],
   "source": [
    "path = \"../../../data/users/\"\n",
    "files = [f.absolute() for f in Path(path).joinpath(\"raw/\").glob(\"*.csv\")]\n",
    "user_stats = path + 'users.sqlite.db'\n",
    "\n",
    "print(\"Total files to process: {}\".format(len(files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 488/488 [30:37<00:00,  3.77s/it]  \n"
     ]
    }
   ],
   "source": [
    "cols_to_read = [\"user_name\", \"no_posts\", \"no_comments\", \"post_karma\", \"comment_karma\", \"first_date\", \"last_date\"] #skip the large json columns\n",
    "\n",
    "def get_file(f):\n",
    "    return pl.scan_csv(f).select(cols_to_read).with_columns([\n",
    "        pl.col(\"first_date\").apply(lambda x: int(time.mktime(datetime.date.fromisoformat(x).timetuple()))),\n",
    "        pl.col(\"last_date\").apply(lambda x: int(time.mktime(datetime.date.fromisoformat(x).timetuple())))\n",
    "    ]).collect()\n",
    "\n",
    "#read in the first file to serve as the baseline\n",
    "df = get_file(files[0])\n",
    "\n",
    "#read in all other files and groupby / add up statistics after each file\n",
    "for f in tqdm(files[1:]):    \n",
    "    new_df = get_file(f)\n",
    "    df.vstack(new_df, in_place=True)\n",
    "    df = df.lazy().groupby(\"user_name\").agg([\n",
    "        pl.col(\"no_posts\").sum(),\n",
    "        pl.col(\"no_comments\").sum(),\n",
    "        pl.col(\"post_karma\").sum(),\n",
    "        pl.col(\"comment_karma\").sum(),\n",
    "        pl.col(\"first_date\").min(),\n",
    "        pl.col(\"last_date\").max()\n",
    "    ]).collect()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add an extra column that captures total activity\n",
    "df = df.with_columns([(pl.col(\"no_posts\") + pl.col(\"no_comments\")).alias(\"total_activity\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "814353"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect(user_stats)\n",
    "df.to_pandas().to_sql(\"users\", conn, index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "458e57744219fd35e36fe617bee87769eccb7cd58eff0111259e94f378fae128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
