{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07JvInQtJxrt"
      },
      "source": [
        "##Install necessary modules"
      ],
      "id": "07JvInQtJxrt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEe1vcO-rNy4",
        "outputId": "661ab1b6-ee6f-46dc-b8f0-275c2aa4c640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.17.0\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 10.1 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 33.5 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 16.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0) (1.21.5)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 30.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17.0) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.17.0) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.17.0) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.17.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.17.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.17.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.17.0) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.17.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.17.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.17.0) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.17.0\n",
            "Collecting detoxify\n",
            "  Downloading detoxify-0.5.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from detoxify) (1.10.0+cu111)\n",
            "Collecting sentencepiece>=0.1.94\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 10.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: transformers!=4.18.0 in /usr/local/lib/python3.7/dist-packages (from detoxify) (4.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->detoxify) (4.1.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers!=4.18.0->detoxify) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers!=4.18.0->detoxify) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers!=4.18.0->detoxify) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers!=4.18.0->detoxify) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers!=4.18.0->detoxify) (0.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers!=4.18.0->detoxify) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers!=4.18.0->detoxify) (1.21.5)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers!=4.18.0->detoxify) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers!=4.18.0->detoxify) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers!=4.18.0->detoxify) (4.11.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers!=4.18.0->detoxify) (0.0.49)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers!=4.18.0->detoxify) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers!=4.18.0->detoxify) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers!=4.18.0->detoxify) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers!=4.18.0->detoxify) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers!=4.18.0->detoxify) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers!=4.18.0->detoxify) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers!=4.18.0->detoxify) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers!=4.18.0->detoxify) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers!=4.18.0->detoxify) (1.15.0)\n",
            "Installing collected packages: sentencepiece, detoxify\n",
            "Successfully installed detoxify-0.5.0 sentencepiece-0.1.96\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.1.0-py3-none-any.whl (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 10.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.5.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 38.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 25.5 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 50.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 47.9 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 35.7 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 49.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.1.0 frozenlist-1.3.0 fsspec-2022.3.0 multidict-6.0.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.17.0\n",
        "!pip install detoxify\n",
        "!pip install datasets\n",
        "# !pip install autoPytorch"
      ],
      "id": "NEe1vcO-rNy4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYx5f_O4J02E"
      },
      "source": [
        "##Connecting to Drive stuff. \n",
        "Mount + go to correct directory"
      ],
      "id": "PYx5f_O4J02E"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jox6rLZ7tkb7",
        "outputId": "179a2d0a-c8c5-48d1-f436-90b764fc7390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "Jox6rLZ7tkb7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryEbzbf2tppi",
        "outputId": "a709f11f-da7f-4e62-93db-34c158770ffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/CSS Project\n"
          ]
        }
      ],
      "source": [
        "path = 'drive/MyDrive/Colab Notebooks/CSS Project' \n",
        "%cd $path"
      ],
      "id": "ryEbzbf2tppi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extremely Important Imports"
      ],
      "metadata": {
        "id": "kkgosNzuF8av"
      },
      "id": "kkgosNzuF8av"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "j7f7t7phF5cm"
      },
      "id": "j7f7t7phF5cm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhvoO7RaMUFo"
      },
      "source": [
        "##Visualizing data through counting the # of each class."
      ],
      "id": "FhvoO7RaMUFo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKVVHLUFGq93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa46cc1b-4367-4e5d-f31e-e75051e08392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({14: 269, 8: 116, 4: 111, 1: 104, 5: 89, 17: 67, 18: 66, 23: 35, 19: 32, 13: 13, 11: 13, 7: 12, 21: 12, 2: 10, 20: 10, 22: 9, 6: 8, 10: 8, 15: 7, 0: 6, 9: 4, 12: 4, 3: 1, 16: 1})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Function that counts the number of each label in a csv\n",
        "def count_labels(df):\n",
        "  classes = df[\"class\"]\n",
        "  return Counter(classes)\n",
        "\n",
        "path = 'Clean_Post_data.csv'\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "print(count_labels(df))"
      ],
      "id": "aKVVHLUFGq93"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yxa10JPMft5"
      },
      "source": [
        "## Two class shifts. \n",
        "1. Data centric. Focus on clustering data by shape to improve topic models. \n",
        "2. Content centric. Focus on clustering data by content for visualization/information purposes.\n",
        "\n",
        "23 classes is a lot. Some classes can fit within the same label, so we shrink the classes a bit. "
      ],
      "id": "7yxa10JPMft5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHRXj-od6FPL",
        "outputId": "9d8fd3dc-2834-44aa-fcf8-e689bc36f73b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  link  class\n",
            "190  https://www.reddit.com/r/antiwork/comments/qmy...      7\n",
            "191  https://www.reddit.com/r/antiwork/comments/qst...      9\n",
            "192  https://www.reddit.com/r/antiwork/comments/r1l...      9\n",
            "193  https://www.reddit.com/r/antiwork/comments/r3a...     12\n",
            "194  https://www.reddit.com/r/antiwork/comments/reh...     11\n",
            "195  https://www.reddit.com/r/antiwork/comments/riq...      9\n",
            "196  https://www.reddit.com/r/antiwork/comments/rqw...      2\n",
            "197  https://www.reddit.com/r/antiwork/comments/s1f...      7\n",
            "198  https://www.reddit.com/r/antiwork/comments/s3d...      3\n",
            "199  https://www.reddit.com/r/antiwork/comments/sbh...      4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 6,\n",
              "         1: 104,\n",
              "         2: 51,\n",
              "         3: 111,\n",
              "         4: 89,\n",
              "         5: 8,\n",
              "         6: 12,\n",
              "         7: 120,\n",
              "         8: 8,\n",
              "         9: 282,\n",
              "         10: 13,\n",
              "         11: 74,\n",
              "         12: 66,\n",
              "         13: 32,\n",
              "         14: 10,\n",
              "         15: 12,\n",
              "         16: 9})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Function that transforms raw classes to data classes. All hardcoded.\n",
        "# Information about specific class tags are in the main spreadsheet\n",
        "\n",
        "def data_label_shift(df):\n",
        "  df['class'] = df['class'].map(lambda label: data_shift_rules(label))\n",
        "  return df\n",
        "\n",
        "def data_shift_rules(val):\n",
        "  # bucket_0 = [0, 1]\n",
        "  # bucket_1 = [2, 3, 9, 13, 16, 20, 23]\n",
        "  # bucket_2 = [4]\n",
        "  # bucket_3 = [5]\n",
        "  # bucket_4 = [6, 7, 8, 10, 12]\n",
        "  # bucket_5 = [11, 14]\n",
        "  # bucket_6 = [15, 17]\n",
        "  # bucket_7 = [18, 19, 21, 22]\n",
        "  bucket_0 = [0]\n",
        "  bucket_1 = [1]\n",
        "  bucket_2 = [2]\n",
        "  bucket_3 = [3]\n",
        "  bucket_4 = [4]\n",
        "  bucket_5 = [5]\n",
        "  bucket_6 = [6]\n",
        "  bucket_7 = [7, 8, 9, 10]\n",
        "  buckets = [bucket_0, bucket_1, bucket_2, bucket_3, bucket_4, bucket_5, bucket_6, bucket_7]\n",
        "  for i in range(len(buckets)):\n",
        "    if val in buckets[i]:\n",
        "      return i\n",
        "# Function that transforms raw classes to content classes. All hardcoded.\n",
        "# Information about specific class tags are in the main spreadsheet\n",
        "\n",
        "def content_label_shift(df):\n",
        "  df['class'] = df['class'].map(lambda label: content_shift_rules(label))\n",
        "  return df\n",
        "def content_shift_rules(val):\n",
        "  b_0 = [0]\n",
        "  b_1 = [1]\n",
        "  b_2 = [2, 3, 9, 16, 23]\n",
        "  b_3 = [4]\n",
        "  b_4 = [5]\n",
        "  b_5 = [6]\n",
        "  b_6 = [7]\n",
        "  b_7 = [8, 12]\n",
        "  b_8 = [10]\n",
        "  b_9 = [11, 14]\n",
        "  b_10 = [13]\n",
        "  b_11 = [15, 17]\n",
        "  b_12 = [18]\n",
        "  b_13 = [19]\n",
        "  b_14 = [20]\n",
        "  b_15 = [21]\n",
        "  b_16 = [22]\n",
        "  buckets = [b_0, b_1, b_2, b_3, b_4, b_5, b_6, b_7, b_8, b_9, b_10, b_11, b_12, b_13, b_14, b_15, b_16]\n",
        "  for i in range(len(buckets)):\n",
        "    if val in buckets[i]:\n",
        "      return i\n",
        "#Function that splits squeezed data into binary classes (personal story/not personal story)\n",
        "def data_label_shift(df):\n",
        "  df['class'] = df['class'].map(lambda label: data_shift_rules(label))\n",
        "  return df\n",
        "def binary_shift_rules(val):\n",
        "  bucket_0 = [5]\n",
        "  bucket_1 = [0, 1, 2, 3, 4, 6, 7]\n",
        "  buckets = [bucket_0, bucket_1]\n",
        "  for i in range(len(buckets)):\n",
        "    if val in buckets[i]:\n",
        "      return i\n",
        "def binary_label_shift(df):\n",
        "  df['class'] = df['class'].map(lambda label: binary_shift_rules(label))\n",
        "  return df\n",
        "  \n",
        "df = pd.read_csv(\"Clean_Post_data.csv\")\n",
        "df = content_label_shift(df)\n",
        "df.to_csv(\"Content_Post_data.csv\")\n",
        "print(df[190:200])\n",
        "count_labels(df)"
      ],
      "id": "wHRXj-od6FPL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDa4XlW7PPGq"
      },
      "source": [
        "## Adding an ID row from the url\n",
        "ID row helps connect this spreadsheet with the raw data for df merges."
      ],
      "id": "BDa4XlW7PPGq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97c5b888",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "249d60d1-2e05-4254-85e2-cc5067dc1519"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       id                                               link  class\n",
            "0  39l6fp  https://www.reddit.com/r/antiwork/comments/39l...      0\n",
            "1  4l6zjo  https://www.reddit.com/r/antiwork/comments/4l6...      0\n",
            "2  3cbv5q  https://www.reddit.com/r/antiwork/comments/3cb...      0\n",
            "3  3omed5  https://www.reddit.com/r/antiwork/comments/3om...      0\n",
            "4  2twexa  https://www.reddit.com/r/antiwork/comments/2tw...      0\n",
            "5  3u8c8t  https://www.reddit.com/r/antiwork/comments/3u8...      0\n",
            "6  351qkm  https://www.reddit.com/r/antiwork/comments/351...      1\n",
            "7  3auv1l  https://www.reddit.com/r/antiwork/comments/3au...      0\n",
            "8  4og00w  https://www.reddit.com/r/antiwork/comments/4og...      0\n",
            "9  4eaw1n  https://www.reddit.com/r/antiwork/comments/4ea...      0\n"
          ]
        }
      ],
      "source": [
        "# Already ran, but this method pulls the ID from each reddit link and adds it as an extra column. This ID column allows DF merges\n",
        "def add_id_row(df):\n",
        "    ids = []\n",
        "    for index, row in df.iterrows():\n",
        "        k = row['link'].split('/')\n",
        "        ids.append(k[6])\n",
        "    df.insert(0, \"id\", ids, True)\n",
        "    df.to_csv('Clean_Post_Data.csv')\n",
        "    print(df[0:10])\n",
        "add_id_row(df)"
      ],
      "id": "97c5b888"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWDyo50WPY3b"
      },
      "source": [
        "## Adding raw features\n",
        "Just a simple merge with the original raw spreadsheet. The labeled data just has url + class, raw has everything else (text, is_image, etc.)"
      ],
      "id": "kWDyo50WPY3b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c15ec9a6",
        "outputId": "8437a0b1-688e-4770-f54c-5e1a5ffc9216"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       id                                               link  class  \\\n",
            "0  39l6fp  https://www.reddit.com/r/antiwork/comments/39l...      0   \n",
            "1  4l6zjo  https://www.reddit.com/r/antiwork/comments/4l6...      0   \n",
            "2  3cbv5q  https://www.reddit.com/r/antiwork/comments/3cb...      0   \n",
            "3  3omed5  https://www.reddit.com/r/antiwork/comments/3om...      0   \n",
            "4  2twexa  https://www.reddit.com/r/antiwork/comments/2tw...      0   \n",
            "5  3u8c8t  https://www.reddit.com/r/antiwork/comments/3u8...      0   \n",
            "6  351qkm  https://www.reddit.com/r/antiwork/comments/351...      1   \n",
            "7  3auv1l  https://www.reddit.com/r/antiwork/comments/3au...      0   \n",
            "8  4og00w  https://www.reddit.com/r/antiwork/comments/4og...      0   \n",
            "9  4eaw1n  https://www.reddit.com/r/antiwork/comments/4ea...      0   \n",
            "\n",
            "                                               title  \\\n",
            "0  Temp Hides Fun, Fulfilling Life From Rest Of O...   \n",
            "1                                Your Life Is Wasted   \n",
            "2  Study: Many admit to drinking, doing drugs whi...   \n",
            "3  You have to work 100 hours a week to get by on...   \n",
            "4  Some Advice for John Dishwasher (AbolishWork.com)   \n",
            "5  The CIA’s WWII Guide to Creating Organizationa...   \n",
            "6                    The essential anti-work library   \n",
            "7         Disabled workers forced to take unfit jobs   \n",
            "8  How insane work hours became a mark of America...   \n",
            "9  For Staff on ‘Naked and Afraid,’ Work Is Just ...   \n",
            "\n",
            "                                                body is_image  \\\n",
            "0                                                NaN    False   \n",
            "1                                                NaN    False   \n",
            "2                                                NaN    False   \n",
            "3                                                NaN    False   \n",
            "4                                                NaN    False   \n",
            "5                                                NaN    False   \n",
            "6  here's a compilation i made of essential anti-...    False   \n",
            "7                                                NaN    False   \n",
            "8                                                NaN    False   \n",
            "9                                                NaN    False   \n",
            "\n",
            "                author                                                url  \\\n",
            "0              yayfall  http://www.theonion.com/article/temp-hides-fun...   \n",
            "1  diversity_is_racism  http://www.amerika.org/science/your-life-is-wa...   \n",
            "2    fullmaltalchemist  http://blog.sfgate.com/gettowork/2015/07/06/em...   \n",
            "3           witchsbrew  http://www.marketwatch.com/story/you-have-to-w...   \n",
            "4          AbolishWork  http://abolishwork.com/2015/01/25/advice-john-...   \n",
            "5    CherenkovRadiator  http://www.slate.com/blogs/the_vault/2015/11/2...   \n",
            "6        TheGoldenRoad  http://www.reddit.com/r/antiwork/comments/351q...   \n",
            "7              andoruB  http://theguardian.com/society/2015/jun/23/dis...   \n",
            "8  diversity_is_racism  http://theweek.com/articles/629256/how-insane-...   \n",
            "9   phoenix--insurgent  http://www.nytimes.com/2016/04/11/business/med...   \n",
            "\n",
            "   num_comments  num_upvotes  \n",
            "0           0.0         15.0  \n",
            "1           0.0          1.0  \n",
            "2           2.0         13.0  \n",
            "3           0.0         18.0  \n",
            "4           0.0          8.0  \n",
            "5           0.0         25.0  \n",
            "6          14.0         39.0  \n",
            "7           0.0          7.0  \n",
            "8           0.0          1.0  \n",
            "9           0.0          9.0  \n"
          ]
        }
      ],
      "source": [
        "all_submissions_path = 'all_submissions.csv'\n",
        "\n",
        "# Merges labeled data with raw dataset to pull all features\n",
        "def add_raw_features(df, raw_data_path):\n",
        "    clean = df\n",
        "    raw = pd.read_csv(raw_data_path, index_col = 0)\n",
        "    merged = pd.merge(clean, raw, left_on=\"id\", right_on=\"id\", how=\"left\")\n",
        "    print(merged[0:10])\n",
        "    return merged\n",
        "df = add_raw_features(df, all_submissions_path)"
      ],
      "id": "c15ec9a6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzHAiuTEPlWk"
      },
      "source": [
        "# Random Forest\n",
        "We will attempt to use the random forest to build a baseline classifier that only uses text and post features. \n",
        "\n",
        "We are adding several extra text features here.\n",
        " That is, number of unique words in a post, name of the linked URL, and the length of the post (which isn't added here but is in the main function)"
      ],
      "id": "HzHAiuTEPlWk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1Q0LADa5CsA"
      },
      "outputs": [],
      "source": [
        "## Function that counts unique words. Used as lambda function.\n",
        "def count_unique_words(data):\n",
        "    data = data.split(' ')\n",
        "    count = len(set(data))\n",
        "    return count\n",
        "\n",
        "## Function that pulls the site from the supplied link\n",
        "## This helps differentiate links/images from normal text because they will link to a different site\n",
        "## Sometimes there is no link. Replaced with \"None\"\n",
        "\n",
        "def pull_name_from_url(url):\n",
        "    if type(url) != str:\n",
        "      return \"None\"\n",
        "    parts = url.split('/')\n",
        "    name = parts[2]\n",
        "    return name\n",
        "\n",
        "# pull_name_from_url(\"https://www.theonion.com/article/temp-hides-fun\")"
      ],
      "id": "x1Q0LADa5CsA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLnjmzvrJ5BS"
      },
      "source": [
        "#Instantiate models to derive features from text\n",
        "\n",
        "## There are 4 features.\n",
        "1. Toxicity of text\n",
        "2. Emotional sentiment of text (Sad, happy, angry)\n",
        "3. Valence of text (Positive, Neutral, Negative)\n",
        "4. Valence score (0 - 1)"
      ],
      "id": "GLnjmzvrJ5BS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0e583a45"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from detoxify import Detoxify\n",
        "\n",
        "toxicity_model = Detoxify('unbiased', device='cuda')\n",
        "emotion_sentiment_model = pipeline(\"text-classification\",model='bhadresh-savani/bert-base-uncased-emotion', return_all_scores=False, truncation = True)\n",
        "valence_model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
        "valence_sentiment_model = pipeline(\"sentiment-analysis\", model = valence_model_path, tokenizer = valence_model_path, max_length = 512, truncation = True)\n",
        "# path = '../../data/labeled_data/Clean_Post_Data.csv'"
      ],
      "id": "0e583a45"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzRhsVERKSKF"
      },
      "source": [
        "## Sanity test to make sure models are working"
      ],
      "id": "RzRhsVERKSKF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvMDdiJ6wQrF",
        "outputId": "44344ef3-d182-4f53-bdde-e05acea0caf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'toxicity': 0.0031205649, 'severe_toxicity': 1.3883252e-05, 'obscene': 0.00019282907, 'identity_attack': 0.0005151768, 'insult': 0.0007259051, 'threat': 9.910632e-05, 'sexual_explicit': 0.00024452267}\n",
            "[{'label': 'anger', 'score': 0.7847622036933899}]\n",
            "[{'label': 'Negative', 'score': 0.8896994590759277}]\n"
          ]
        }
      ],
      "source": [
        "print(toxicity_model.predict(\"Man work is rough\"))\n",
        "print(emotion_sentiment_model(\"Man work is rough\"))\n",
        "print(valence_sentiment_model(\"Man work is rough\"))"
      ],
      "id": "NvMDdiJ6wQrF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHiNXEUERnUb"
      },
      "source": [
        "## Adding all extra features to the dataframe & saving as CSV"
      ],
      "id": "dHiNXEUERnUb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ea036b2f"
      },
      "outputs": [],
      "source": [
        "def add_extra_features(df):\n",
        "\n",
        "    df['body'] = df['body'].map(lambda body: str(body))\n",
        "    df['title'] = df['title'].map(lambda title: str(title))\n",
        "    \n",
        "    df['length'] = df['body'].map(lambda body: len(body))\n",
        "    df['count'] = df['body'].map(lambda body: count_unique_words(body))\n",
        "    df['linked_site'] = df['url'].map(lambda url: pull_name_from_url(url))\n",
        "\n",
        "    df['title_emotion'] = df['title'].map(lambda title: emotion_sentiment_model(title)[0]['label'])\n",
        "    df['title_valence'] = df['title'].map(lambda title: valence_sentiment_model(title)[0]['label'])\n",
        "    df['title_valence_score'] = df['title'].map(lambda title: valence_sentiment_model(title)[0]['score'])\n",
        "    df['title_toxicity'] = df['title'].map(lambda title: toxicity_model.predict(title)['toxicity'])\n",
        "\n",
        "    df['emotion'] = df['body'].map(lambda body: emotion_sentiment_model(body)[0]['label'])\n",
        "    df['valence'] = df['body'].map(lambda body: valence_sentiment_model(body)[0]['label'])\n",
        "    df['valence_score'] = df['body'].map(lambda body: valence_sentiment_model(body)[0]['score'])\n",
        "    df['toxicity'] = df['body'].map(lambda body: toxicity_model.predict(body)['toxicity'])\n",
        "    df.to_csv(\"data_extra_features.csv\")\n",
        "    return df\n",
        "    # 3. sentiment of the text\n",
        "    # 4. Toxicity of the text\n",
        "    # 5. url of the text\n",
        "df = add_extra_features(df)\n",
        "\n",
        "# df[\"combined\"] = df[\"title\"] + ' ' + df[\"body\"]"
      ],
      "id": "ea036b2f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaVWO5TiLeFW"
      },
      "source": [
        "##Plotting counts of all data"
      ],
      "id": "JaVWO5TiLeFW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAB6Du1jUzCV"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data_extra_features_binary.csv\", index_col = 0)\n",
        "# df = df.fillna('')\n",
        "# meme_df = df[(df['class'] == 3)] # Longer than tweet/other image, count is inbetween tweet/other image. More negative in valence\n",
        "# meme_hist = meme_df.hist('title_toxicity', bins = 50)\n",
        "# meme_bar = meme_df['is_image'].value_counts().plot(kind='bar')\n",
        "\n",
        "# tweet_df = df[(df['class'] == 7)] #Length inbetween tweet and other image, longest count.\n",
        "# tweet_hist = tweet_df.hist('title_toxicity', bins = 50)\n",
        "# tweet_bar = tweet_df['is_image'].value_counts().plot(kind='bar')\n",
        "\n",
        "# other_image_df = df[(df['class'] == 4)] # Least count/length. Much happier emotion\n",
        "# other_image_is_image_df = other_image_df[(other_image_df['is_image'] == False)]\n",
        "# pd.set_option('display.max_colwidth',1000)\n",
        "\n",
        "# print(other_image_is_image_df['link'])\n",
        "# other_hist = other_image_df.hist('title_toxicity', bins = 50)\n",
        "# other_image_bar = other_image_df['is_image'].value_counts().plot(kind='bar') \n",
        "\n",
        "# Plot distributions of length, count, toxicity \n",
        "# hist = df.hist('title_emotion', bins = 50) # Works for all numerical values\n",
        "\n",
        "# Plot counts of sentiment, valence, linked_site\n",
        "# bar = df['title_valence'].value_counts()[:20].plot(kind='bar') # Works for all nominal values\n",
        "\n",
        "# Plot distribution of positive valence scores\n",
        "# positive_df = df[(df['title_valence'] == \"Positive\")]\n",
        "# positive_hist = positive_df.hist('valence_score', bins = 50)\n",
        "\n",
        "# Plot distribution of neutral valence scores\n",
        "# neutral_df = df[(df['title_valence'] == \"Neutral\")]\n",
        "# neutral_hist = neutral_df.hist('valence_score', bins = 50)\n",
        "\n",
        "# Plot distribution of negative valence scores\n",
        "# negative_df = df[(df['title_valence'] == \"Negative\")]\n",
        "# negative_hist = negative_df.hist('valence_score', bins = 50)"
      ],
      "id": "dAB6Du1jUzCV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWIhYu7zKnac"
      },
      "source": [
        "## Mapping text features to numbers"
      ],
      "id": "fWIhYu7zKnac"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMnSxf9LUKuZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d8369c3-354c-464c-8ae4-db40d048defa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       id                                               link  class  \\\n",
            "0  39l6fp  https://www.reddit.com/r/antiwork/comments/39l...      1   \n",
            "1  4l6zjo  https://www.reddit.com/r/antiwork/comments/4l6...      1   \n",
            "2  3cbv5q  https://www.reddit.com/r/antiwork/comments/3cb...      1   \n",
            "3  3omed5  https://www.reddit.com/r/antiwork/comments/3om...      1   \n",
            "4  2twexa  https://www.reddit.com/r/antiwork/comments/2tw...      1   \n",
            "5  3u8c8t  https://www.reddit.com/r/antiwork/comments/3u8...      1   \n",
            "6  351qkm  https://www.reddit.com/r/antiwork/comments/351...      1   \n",
            "7  3auv1l  https://www.reddit.com/r/antiwork/comments/3au...      1   \n",
            "8  4og00w  https://www.reddit.com/r/antiwork/comments/4og...      1   \n",
            "9  4eaw1n  https://www.reddit.com/r/antiwork/comments/4ea...      1   \n",
            "\n",
            "                                               title  \\\n",
            "0  Temp Hides Fun, Fulfilling Life From Rest Of O...   \n",
            "1                                Your Life Is Wasted   \n",
            "2  Study: Many admit to drinking, doing drugs whi...   \n",
            "3  You have to work 100 hours a week to get by on...   \n",
            "4  Some Advice for John Dishwasher (AbolishWork.com)   \n",
            "5  The CIA’s WWII Guide to Creating Organizationa...   \n",
            "6                    The essential anti-work library   \n",
            "7         Disabled workers forced to take unfit jobs   \n",
            "8  How insane work hours became a mark of America...   \n",
            "9  For Staff on ‘Naked and Afraid,’ Work Is Just ...   \n",
            "\n",
            "                                                body  is_image  \\\n",
            "0                                                NaN       0.0   \n",
            "1                                                NaN       0.0   \n",
            "2                                                NaN       0.0   \n",
            "3                                                NaN       0.0   \n",
            "4                                                NaN       0.0   \n",
            "5                                                NaN       0.0   \n",
            "6  here's a compilation i made of essential anti-...       0.0   \n",
            "7                                                NaN       0.0   \n",
            "8                                                NaN       0.0   \n",
            "9                                                NaN       0.0   \n",
            "\n",
            "                author                                                url  \\\n",
            "0              yayfall  http://www.theonion.com/article/temp-hides-fun...   \n",
            "1  diversity_is_racism  http://www.amerika.org/science/your-life-is-wa...   \n",
            "2    fullmaltalchemist  http://blog.sfgate.com/gettowork/2015/07/06/em...   \n",
            "3           witchsbrew  http://www.marketwatch.com/story/you-have-to-w...   \n",
            "4          AbolishWork  http://abolishwork.com/2015/01/25/advice-john-...   \n",
            "5    CherenkovRadiator  http://www.slate.com/blogs/the_vault/2015/11/2...   \n",
            "6        TheGoldenRoad  http://www.reddit.com/r/antiwork/comments/351q...   \n",
            "7              andoruB  http://theguardian.com/society/2015/jun/23/dis...   \n",
            "8  diversity_is_racism  http://theweek.com/articles/629256/how-insane-...   \n",
            "9   phoenix--insurgent  http://www.nytimes.com/2016/04/11/business/med...   \n",
            "\n",
            "   num_comments  num_upvotes  ...  linked_site  emotion  valence  \\\n",
            "0           0.0         15.0  ...            4        0        1   \n",
            "1           0.0          1.0  ...           69        0        1   \n",
            "2           2.0         13.0  ...           16        0        1   \n",
            "3           0.0         18.0  ...           48        0        1   \n",
            "4           0.0          8.0  ...            2        0        1   \n",
            "5           0.0         25.0  ...           17        0        1   \n",
            "6          14.0         39.0  ...            0        0        1   \n",
            "7           0.0          7.0  ...           49        0        1   \n",
            "8           0.0          1.0  ...           50        0        1   \n",
            "9           0.0          9.0  ...            8        0        1   \n",
            "\n",
            "   valence_score  toxicity  title_emotion  title_valence  title_valence_score  \\\n",
            "0       0.395947  0.000701              2              2             0.820678   \n",
            "1       0.395947  0.000701              4              0             0.861215   \n",
            "2       0.395947  0.000701              0              1             0.711456   \n",
            "3       0.395947  0.000701              2              1             0.542162   \n",
            "4       0.395947  0.000701              2              1             0.829223   \n",
            "5       0.395947  0.000701              0              1             0.511383   \n",
            "6       0.405582  0.124241              2              1             0.563766   \n",
            "7       0.395947  0.000701              4              0             0.839482   \n",
            "8       0.395947  0.000701              0              0             0.490790   \n",
            "9       0.395947  0.000701              1              1             0.510382   \n",
            "\n",
            "   title_toxicity                                           combined  \n",
            "0        0.001104  Temp Hides Fun, Fulfilling Life From Rest Of O...  \n",
            "1        0.189686                               Your Life Is Wasted   \n",
            "2        0.003765  Study: Many admit to drinking, doing drugs whi...  \n",
            "3        0.000616  You have to work 100 hours a week to get by on...  \n",
            "4        0.000540  Some Advice for John Dishwasher (AbolishWork.c...  \n",
            "5        0.000768  The CIA’s WWII Guide to Creating Organizationa...  \n",
            "6        0.001172  The essential anti-work library here's a compi...  \n",
            "7        0.013525        Disabled workers forced to take unfit jobs   \n",
            "8        0.030477  How insane work hours became a mark of America...  \n",
            "9        0.007661  For Staff on ‘Naked and Afraid,’ Work Is Just ...  \n",
            "\n",
            "[10 rows x 22 columns]\n"
          ]
        }
      ],
      "source": [
        "# def cat_to_num(df, categories):\n",
        "#   for i in categories:\n",
        "#     df[i] = df[i].astype('category')\n",
        "#     df[i] = df[i].cat.codes\n",
        "#   return df\n",
        "# df = cat_to_num(df, ['linked_site', 'emotion', 'title_valence', 'title_emotion', 'valence', 'is_image'])\n",
        "valence_mapping = {label:idx for idx,label in enumerate(np.unique(df['valence']))}\n",
        "emotion_mapping = {label:idx for idx,label in enumerate(np.unique(df['emotion']))}\n",
        "\n",
        "title_valence_mapping = {label:idx for idx,label in enumerate(np.unique(df['title_valence']))}\n",
        "title_emotion_mapping = {label:idx for idx,label in enumerate(np.unique(df['title_emotion']))}\n",
        "# Done by count for implicit bias purposes\n",
        "site_mapping = {label:idx for idx,label in enumerate(df['linked_site'].value_counts().index)}\n",
        "\n",
        "def is_image_mapping(val):\n",
        "  if val == False:\n",
        "    return 0\n",
        "  if val == True:\n",
        "    return 1\n",
        "\n",
        "def text_to_num_features(df):\n",
        "  df['linked_site'] = df['linked_site'].map(lambda site: site_mapping[site])\n",
        "  df['emotion'] = df['emotion'].map(lambda emotion: emotion_mapping[emotion])\n",
        "  df['title_valence'] = df['title_valence'].map(lambda valence: valence_mapping[valence])\n",
        "  df['title_emotion'] = df['title_emotion'].map(lambda emotion: emotion_mapping[emotion])\n",
        "  df['valence'] = df['valence'].map(lambda valence: valence_mapping[valence])\n",
        "  df['is_image'] = df['is_image'].map(lambda val: is_image_mapping(val))\n",
        "  print(df[0:10])\n",
        "  return df\n",
        "df = text_to_num_features(df)"
      ],
      "id": "uMnSxf9LUKuZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Checking for invalid values"
      ],
      "metadata": {
        "id": "W75iMgl0FRQ2"
      },
      "id": "W75iMgl0FRQ2"
    },
    {
      "cell_type": "code",
      "source": [
        "# print(np.any(np.isnan(df)))\n",
        "# print(np.all(np.isfinite(df)))"
      ],
      "metadata": {
        "id": "WJowbmbmquHD"
      },
      "id": "WJowbmbmquHD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUFrH7-kLRKm"
      },
      "source": [
        "## Dropping useless categories"
      ],
      "id": "EUFrH7-kLRKm"
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_categories(df):\n",
        "  df = df.drop(columns = ['id', 'link', 'title', 'body', 'author', 'url', 'combined'])\n",
        "  return df\n",
        "# Label set\n",
        "df = drop_categories(df)\n",
        "y = df[\"class\"]\n",
        "df = df.drop(columns = \"class\")\n",
        "for i in df['linked_site']:\n",
        "  print(type(i))\n",
        "# df = df.astype(float)\n",
        "\n",
        "print(df[0:10])"
      ],
      "metadata": {
        "id": "BfmLETGn7JqM"
      },
      "id": "BfmLETGn7JqM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2M7yg7aLoVE"
      },
      "source": [
        "## Normalize data\n",
        "\n"
      ],
      "id": "J2M7yg7aLoVE"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled_df = scaler.fit_transform(df)\n",
        "\n",
        "df = pd.DataFrame(scaled_df, columns = df.columns, index = df.index)\n",
        "df = df.fillna(df.median())\n",
        "print(df)\n",
        "\n",
        "\n",
        "# df.to_csv(\"rf_data.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LmnMosz97rT",
        "outputId": "cfc38863-c35b-4b5f-bb78-25bc1597a962"
      },
      "id": "8LmnMosz97rT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      is_image  num_comments  num_upvotes    length     count  linked_site  \\\n",
            "0          0.0      0.000000     0.009603  0.000062  0.000000     0.054795   \n",
            "1          0.0      0.000000     0.000640  0.000062  0.000000     0.945205   \n",
            "2          0.0      0.000261     0.008323  0.000062  0.000000     0.219178   \n",
            "3          0.0      0.000000     0.011524  0.000062  0.000000     0.657534   \n",
            "4          0.0      0.000000     0.005122  0.000062  0.000000     0.027397   \n",
            "...        ...           ...          ...       ...       ...          ...   \n",
            "1014       1.0      0.000261     0.017926  0.007664  0.014370     0.013699   \n",
            "1015       0.0      0.000392     0.017926  0.211900  0.258664     0.000000   \n",
            "1016       0.0      0.000261     0.005122  0.000062  0.000000     0.027397   \n",
            "1017       0.0      0.000131     0.004481  0.000062  0.000000     0.136986   \n",
            "1018       1.0      0.000392     0.000640  0.023364  0.042265     0.013699   \n",
            "\n",
            "      emotion  valence  valence_score  toxicity  title_emotion  title_valence  \\\n",
            "0         0.0      0.5       0.075688  0.000380            0.4            1.0   \n",
            "1         0.0      0.5       0.075688  0.000380            0.8            0.0   \n",
            "2         0.0      0.5       0.075688  0.000380            0.0            0.5   \n",
            "3         0.0      0.5       0.075688  0.000380            0.4            0.5   \n",
            "4         0.0      0.5       0.075688  0.000380            0.4            0.5   \n",
            "...       ...      ...            ...       ...            ...            ...   \n",
            "1014      0.8      0.0       0.946851  0.004718            0.0            0.5   \n",
            "1015      0.0      0.0       0.282928  0.002561            0.4            0.0   \n",
            "1016      0.0      0.5       0.075688  0.000380            0.8            0.5   \n",
            "1017      0.0      0.5       0.075688  0.000380            0.4            1.0   \n",
            "1018      0.4      0.0       0.263435  0.001349            0.4            0.0   \n",
            "\n",
            "      title_valence_score  title_toxicity  \n",
            "0                0.777233        0.000802  \n",
            "1                0.842698        0.190344  \n",
            "2                0.600846        0.003476  \n",
            "3                0.327448        0.000311  \n",
            "4                0.791033        0.000235  \n",
            "...                   ...             ...  \n",
            "1014             0.757998        0.000181  \n",
            "1015             0.225292        0.000451  \n",
            "1016             0.607322        0.120661  \n",
            "1017             0.224216        0.000122  \n",
            "1018             0.893717        0.000337  \n",
            "\n",
            "[1019 rows x 14 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = replacement\n",
        "replacement = df\n",
        "df = df.drop(columns = [\"title_valence_score\", \"title_emotion\", \"title_valence\", \"valence\", \"valence_score\"])\n",
        "print(replacement[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi9LZfN1XeGn",
        "outputId": "9bd54c4e-f796-464e-bb54-13b0360fffd2"
      },
      "id": "Zi9LZfN1XeGn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   is_image  num_comments  num_upvotes    length  count  linked_site  emotion  \\\n",
            "0       0.0      0.000000     0.009603  0.000062    0.0     0.054795      0.0   \n",
            "1       0.0      0.000000     0.000640  0.000062    0.0     0.945205      0.0   \n",
            "2       0.0      0.000261     0.008323  0.000062    0.0     0.219178      0.0   \n",
            "3       0.0      0.000000     0.011524  0.000062    0.0     0.657534      0.0   \n",
            "4       0.0      0.000000     0.005122  0.000062    0.0     0.027397      0.0   \n",
            "\n",
            "   valence  valence_score  toxicity  title_emotion  title_valence  \\\n",
            "0      0.5       0.075688   0.00038            0.4            1.0   \n",
            "1      0.5       0.075688   0.00038            0.8            0.0   \n",
            "2      0.5       0.075688   0.00038            0.0            0.5   \n",
            "3      0.5       0.075688   0.00038            0.4            0.5   \n",
            "4      0.5       0.075688   0.00038            0.4            0.5   \n",
            "\n",
            "   title_valence_score  title_toxicity  \n",
            "0             0.777233        0.000802  \n",
            "1             0.842698        0.190344  \n",
            "2             0.600846        0.003476  \n",
            "3             0.327448        0.000311  \n",
            "4             0.791033        0.000235  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx2jmzvOLq3H"
      },
      "source": [
        "## Run Random Forest"
      ],
      "id": "wx2jmzvOLq3H"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8VYMBl6VKmj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3212e0f5-2669-416b-93ba-a03a454081cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(815, 9) (204, 9)\n",
            "(815,) (204,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2)\n",
        "\n",
        "print(X_train.shape, X_test.shape)\n",
        "print(y_train.shape, y_test.shape)\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "clf.fit(X_train, y_train)"
      ],
      "id": "T8VYMBl6VKmj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxDWZ8pUVZIp"
      },
      "source": [
        "## Visualize impacts of features on results\n",
        "\n",
        "Drop unimportant features"
      ],
      "id": "qxDWZ8pUVZIp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfM3jdGQVaIQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "f2270d73-aefd-4dc7-c1f1-3b959856840e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "## TODO visualize importances of datapoint\n",
        "\n",
        "feature_imp = pd.Series(clf.feature_importances_, index = df.columns).sort_values(ascending=False)\n",
        "\n",
        "#print(\"Accuracy: {}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
        "# Add labels to your graph\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Features')\n",
        "plt.title(\"Visualizing Important Features\")\n",
        "plt.tight_layout()"
      ],
      "id": "CfM3jdGQVaIQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJTLC9BUVnIk"
      },
      "source": [
        "##Visualize RF results\n",
        "\n",
        "Show Confusion matrix <br>\n",
        "Show f1 scores"
      ],
      "id": "eJTLC9BUVnIk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dbovYPqVlh1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "2f1e5c06-9d65-4a21-fee7-f5767fee0285"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Accuracy: 0.7990196078431373\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.68      0.68        65\n",
            "           1       0.85      0.86      0.85       139\n",
            "\n",
            "    accuracy                           0.80       204\n",
            "   macro avg       0.77      0.77      0.77       204\n",
            "weighted avg       0.80      0.80      0.80       204\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "#TODO Show Confusion matrix \n",
        "#TODO Show f1 scores/accuracy\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(\"   Accuracy: {}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.heatmap(conf_matrix, annot=True)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.tight_layout()"
      ],
      "id": "-dbovYPqVlh1"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4uTPaaGSNhJU"
      },
      "id": "4uTPaaGSNhJU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In this section we will test SVM and Logistic Regression <br>\n",
        "We will try SVM on BOW(body) and BOW(title + body) <br>\n",
        "We will try Logistic Regression on BOW(body and BOW(title + body) <br>\n",
        "\n",
        "SVM on body: L2 loss, alpha = 1e-3, max_iter = 3 <br>\n",
        "SVM on combined: L2 loss, alpha = 5e-4, max_iter = 5 <br>\n",
        "\n",
        "Logistic Regression on body: C = 50, max_iter = 16 <br>\n",
        "Logistic Regression on combined: C = 55, max_iter = 30 <br>\n",
        "\n"
      ],
      "metadata": {
        "id": "otM-y7ocGRru"
      },
      "id": "otM-y7ocGRru"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "df = pd.read_csv(\"data_extra_features_binary.csv\", index_col = 0)\n",
        "df = df.fillna('')\n",
        "\n",
        "X = df.combined\n",
        "y = df['class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
        "# for i in range(5, 100, 5):\n",
        "#   for j in range(10, 60, 5):\n",
        "svm = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
        "                  ('tfidf', TfidfTransformer()),\n",
        "                   ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=0.001, random_state=42, max_iter = 3, tol=None)),\n",
        "                  # ('clf', LogisticRegression(n_jobs=1, C = 55, max_iter = 30))\n",
        "                  ])\n",
        "svm.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebGIox1iWOnn",
        "outputId": "55b8841c-c0f0-4a7c-8afe-d4c9a216c460"
      },
      "id": "ebGIox1iWOnn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vect', CountVectorizer(stop_words='english')),\n",
              "                ('tfidf', TfidfTransformer()),\n",
              "                ('clf',\n",
              "                 SGDClassifier(alpha=0.001, max_iter=3, random_state=42,\n",
              "                               tol=None))])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate accuracy on test set"
      ],
      "metadata": {
        "id": "w4UjXhgZRhn0"
      },
      "id": "w4UjXhgZRhn0"
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = svm.predict(X_test)\n",
        "y_train_pred = svm.predict(X_train)\n",
        "\n",
        "print('accuracy %s' % metrics.accuracy_score(y_pred, y_test))\n",
        "# print(classification_report(y_train_pred, y_train,target_names=['0','1', '2', '3', '4', '5', '6', '7'])) # Train Accuracy\n",
        "print(classification_report(y_pred, y_test, target_names=['0','1'])) # Test Accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYFi6U8GIst5",
        "outputId": "dbd8f155-1943-4234-e46c-0a95b963006c"
      },
      "id": "KYFi6U8GIst5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.8774509803921569\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.78      0.77        54\n",
            "           1       0.92      0.91      0.92       150\n",
            "\n",
            "    accuracy                           0.88       204\n",
            "   macro avg       0.84      0.85      0.84       204\n",
            "weighted avg       0.88      0.88      0.88       204\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#In this section we will finetune BERT for classification\n",
        "We will classify body and title + body <br>\n",
        "First, we must load the tokenizer and BERT."
      ],
      "metadata": {
        "id": "FdpuamUXGoUJ"
      },
      "id": "FdpuamUXGoUJ"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import TrainingArguments, Trainer, TrainerCallback\n",
        "from datasets import load_metric\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lteSM1cC7ti",
        "outputId": "ab3e3641-5701-4d1a-ddce-73cae820f2b5"
      },
      "id": "4lteSM1cC7ti",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
            "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n",
            "loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
            "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\",\n",
            "    \"7\": \"LABEL_7\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6,\n",
            "    \"LABEL_7\": 7\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess data to input to the trainer"
      ],
      "metadata": {
        "id": "EFicpYziG488"
      },
      "id": "EFicpYziG488"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"data_extra_features_binary.csv\", index_col = 0)\n",
        "df = df.fillna('')\n",
        "\n",
        "df_bert = pd.DataFrame().assign(label=df['class'], text=df['body'])\n",
        "data = Dataset.from_pandas(df_bert, preserve_index=False)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_dataset = data.map(tokenize_function)\n",
        "print(tokenized_dataset)\n",
        "train_test_dict = tokenized_dataset.train_test_split(test_size=0.2)\n",
        "\n",
        "train = train_test_dict['train']\n",
        "test = train_test_dict['test']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "6ebd9dc6ad3348bdba78c7e84ab97691",
            "04eb6c7853e44ed59f3a7cf0201063f4",
            "36db068be79c4dad996f2426dc6b0b98",
            "3b3007d82b3b4846bfdedcdfea4f36c8",
            "9b4c13dde804491398b9f5f9fcb5f74f",
            "7ad348b196be4585a3e5d294dc44117b",
            "41578523fd3046ae9021970f96217d17",
            "c4d61366dfab46e08e923e4d1e8fb0a2",
            "5784e1993d9e44ef93243101cfbd33e2",
            "d21e8ad2781248d59b128c4672233ff0",
            "55073ed8c84648b08c99e156cb1bbaf8"
          ]
        },
        "id": "PrMrkdDgSzAV",
        "outputId": "c8f9d675-d761-46f1-da8f-85c626d0a5e8"
      },
      "id": "PrMrkdDgSzAV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1019 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ebd9dc6ad3348bdba78c7e84ab97691"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "    num_rows: 1019\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the compute metrics function "
      ],
      "metadata": {
        "id": "_-zZsOKgG-QX"
      },
      "id": "_-zZsOKgG-QX"
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  logits, labels = eval_pred\n",
        "  predictions = np.argmax(logits, axis=-1)\n",
        "  precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='macro')\n",
        "  acc = metric.compute(predictions = predictions, references=labels)['accuracy']\n",
        "  return {\n",
        "      'accuracy': acc,\n",
        "      'f1': f1,\n",
        "      'precision': precision,\n",
        "      'recall': recall\n",
        "  }\n",
        "# def compute_metrics(eval_pred):\n",
        "#     predictions, labels = eval_pred\n",
        "#     predictions = np.argmax(predictions, axis=1)\n",
        "#     return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "4lIhK7bITKze"
      },
      "id": "4lIhK7bITKze",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Add a custom callback to compute train accuracy. "
      ],
      "metadata": {
        "id": "8hyMHeOV17JR"
      },
      "id": "8hyMHeOV17JR"
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "class CustomCallback(TrainerCallback):\n",
        "    \n",
        "    def __init__(self, trainer) -> None:\n",
        "        super().__init__()\n",
        "        self._trainer = trainer\n",
        "    \n",
        "    def on_epoch_end(self, args, state, control, **kwargs):\n",
        "        if control.should_evaluate:\n",
        "          print(\"hello\")\n",
        "          control_copy = deepcopy(control)\n",
        "          self._trainer.evaluate(eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train\")\n",
        "          return control_copy"
      ],
      "metadata": {
        "id": "DReZ0tGbQY7x"
      },
      "id": "DReZ0tGbQY7x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Add training arguments and train.\n",
        "\n",
        "Body only: learning rate = 1e-5, weight_decay = 0 <br>\n",
        "Binary: learning rate = 1e-6, weight_decay = 0\n",
        "\n",
        "Every other line is the training accuracy/testing accuracy. Not sure how to put them side by side"
      ],
      "metadata": {
        "id": "nIK6CRwW9LP7"
      },
      "id": "nIK6CRwW9LP7"
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(output_dir=\"bert_results\", \n",
        "                                  evaluation_strategy=\"epoch\", \n",
        "                                  num_train_epochs = 20, \n",
        "                                  learning_rate = 1e-6, \n",
        "                                  weight_decay = 0.00001,\n",
        "                                  logging_strategy=\"epoch\",\n",
        "                                  logging_dir=\"bert_results/logs\",\n",
        "                                  logging_steps=10)\n",
        "                                  # per_device_train_batch_size = 4,\n",
        "                                  # per_device_eval_batch_size = 4)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train,\n",
        "    eval_dataset=test,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.add_callback(CustomCallback(trainer)) \n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RV5eZnnHS2Z7",
        "outputId": "749092c3-b6a9-4e68-c6e2-e2c77d0a834f"
      },
      "id": "RV5eZnnHS2Z7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 815\n",
            "  Num Epochs = 20\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2040\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2040' max='2040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2040/2040 23:50, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.361919</td>\n",
              "      <td>0.714110</td>\n",
              "      <td>0.277738</td>\n",
              "      <td>0.238329</td>\n",
              "      <td>0.332762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.632500</td>\n",
              "      <td>1.357396</td>\n",
              "      <td>0.735294</td>\n",
              "      <td>0.423729</td>\n",
              "      <td>0.367647</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.632500</td>\n",
              "      <td>1.046926</td>\n",
              "      <td>0.715337</td>\n",
              "      <td>0.417024</td>\n",
              "      <td>0.357669</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.228100</td>\n",
              "      <td>1.048355</td>\n",
              "      <td>0.735294</td>\n",
              "      <td>0.423729</td>\n",
              "      <td>0.367647</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.228100</td>\n",
              "      <td>0.780328</td>\n",
              "      <td>0.746012</td>\n",
              "      <td>0.524894</td>\n",
              "      <td>0.850771</td>\n",
              "      <td>0.555177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.951000</td>\n",
              "      <td>0.791809</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.531034</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>0.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.951000</td>\n",
              "      <td>0.570475</td>\n",
              "      <td>0.883436</td>\n",
              "      <td>0.845957</td>\n",
              "      <td>0.881656</td>\n",
              "      <td>0.823804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.729400</td>\n",
              "      <td>0.601187</td>\n",
              "      <td>0.892157</td>\n",
              "      <td>0.854286</td>\n",
              "      <td>0.876445</td>\n",
              "      <td>0.837778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.729400</td>\n",
              "      <td>0.444631</td>\n",
              "      <td>0.906748</td>\n",
              "      <td>0.884607</td>\n",
              "      <td>0.887762</td>\n",
              "      <td>0.881621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.560700</td>\n",
              "      <td>0.489442</td>\n",
              "      <td>0.877451</td>\n",
              "      <td>0.848642</td>\n",
              "      <td>0.837384</td>\n",
              "      <td>0.863333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.560700</td>\n",
              "      <td>0.367987</td>\n",
              "      <td>0.915337</td>\n",
              "      <td>0.893656</td>\n",
              "      <td>0.903702</td>\n",
              "      <td>0.885029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.460900</td>\n",
              "      <td>0.414025</td>\n",
              "      <td>0.897059</td>\n",
              "      <td>0.868553</td>\n",
              "      <td>0.866443</td>\n",
              "      <td>0.870741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.460900</td>\n",
              "      <td>0.318170</td>\n",
              "      <td>0.916564</td>\n",
              "      <td>0.894156</td>\n",
              "      <td>0.909224</td>\n",
              "      <td>0.881994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.399600</td>\n",
              "      <td>0.364969</td>\n",
              "      <td>0.897059</td>\n",
              "      <td>0.865347</td>\n",
              "      <td>0.872549</td>\n",
              "      <td>0.858889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.399600</td>\n",
              "      <td>0.284214</td>\n",
              "      <td>0.921472</td>\n",
              "      <td>0.906184</td>\n",
              "      <td>0.896638</td>\n",
              "      <td>0.917863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.343500</td>\n",
              "      <td>0.354264</td>\n",
              "      <td>0.887255</td>\n",
              "      <td>0.863569</td>\n",
              "      <td>0.847648</td>\n",
              "      <td>0.887778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.343500</td>\n",
              "      <td>0.257497</td>\n",
              "      <td>0.928834</td>\n",
              "      <td>0.914573</td>\n",
              "      <td>0.906301</td>\n",
              "      <td>0.924307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.305600</td>\n",
              "      <td>0.333780</td>\n",
              "      <td>0.892157</td>\n",
              "      <td>0.868849</td>\n",
              "      <td>0.853571</td>\n",
              "      <td>0.891111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.305600</td>\n",
              "      <td>0.235023</td>\n",
              "      <td>0.932515</td>\n",
              "      <td>0.918696</td>\n",
              "      <td>0.911544</td>\n",
              "      <td>0.926879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.276600</td>\n",
              "      <td>0.317231</td>\n",
              "      <td>0.892157</td>\n",
              "      <td>0.868849</td>\n",
              "      <td>0.853571</td>\n",
              "      <td>0.891111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.276600</td>\n",
              "      <td>0.215621</td>\n",
              "      <td>0.934969</td>\n",
              "      <td>0.921071</td>\n",
              "      <td>0.916521</td>\n",
              "      <td>0.926000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.266000</td>\n",
              "      <td>0.302277</td>\n",
              "      <td>0.901961</td>\n",
              "      <td>0.879547</td>\n",
              "      <td>0.865970</td>\n",
              "      <td>0.897778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.266000</td>\n",
              "      <td>0.206109</td>\n",
              "      <td>0.938650</td>\n",
              "      <td>0.925997</td>\n",
              "      <td>0.919142</td>\n",
              "      <td>0.933763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.253000</td>\n",
              "      <td>0.303548</td>\n",
              "      <td>0.897059</td>\n",
              "      <td>0.874174</td>\n",
              "      <td>0.859676</td>\n",
              "      <td>0.894444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.253000</td>\n",
              "      <td>0.198256</td>\n",
              "      <td>0.941104</td>\n",
              "      <td>0.928957</td>\n",
              "      <td>0.922053</td>\n",
              "      <td>0.936775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.240100</td>\n",
              "      <td>0.302923</td>\n",
              "      <td>0.901961</td>\n",
              "      <td>0.879547</td>\n",
              "      <td>0.865970</td>\n",
              "      <td>0.897778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.240100</td>\n",
              "      <td>0.190855</td>\n",
              "      <td>0.943558</td>\n",
              "      <td>0.932083</td>\n",
              "      <td>0.924272</td>\n",
              "      <td>0.941086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.229100</td>\n",
              "      <td>0.300642</td>\n",
              "      <td>0.901961</td>\n",
              "      <td>0.879547</td>\n",
              "      <td>0.865970</td>\n",
              "      <td>0.897778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.229100</td>\n",
              "      <td>0.185095</td>\n",
              "      <td>0.943558</td>\n",
              "      <td>0.932083</td>\n",
              "      <td>0.924272</td>\n",
              "      <td>0.941086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.225200</td>\n",
              "      <td>0.301550</td>\n",
              "      <td>0.901961</td>\n",
              "      <td>0.879547</td>\n",
              "      <td>0.865970</td>\n",
              "      <td>0.897778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.225200</td>\n",
              "      <td>0.182764</td>\n",
              "      <td>0.947239</td>\n",
              "      <td>0.936893</td>\n",
              "      <td>0.926972</td>\n",
              "      <td>0.948849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.209900</td>\n",
              "      <td>0.306206</td>\n",
              "      <td>0.897059</td>\n",
              "      <td>0.874174</td>\n",
              "      <td>0.859676</td>\n",
              "      <td>0.894444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.209900</td>\n",
              "      <td>0.178820</td>\n",
              "      <td>0.948466</td>\n",
              "      <td>0.938287</td>\n",
              "      <td>0.928723</td>\n",
              "      <td>0.949706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.203300</td>\n",
              "      <td>0.305809</td>\n",
              "      <td>0.897059</td>\n",
              "      <td>0.874174</td>\n",
              "      <td>0.859676</td>\n",
              "      <td>0.894444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.203300</td>\n",
              "      <td>0.176520</td>\n",
              "      <td>0.948466</td>\n",
              "      <td>0.938287</td>\n",
              "      <td>0.928723</td>\n",
              "      <td>0.949706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.198600</td>\n",
              "      <td>0.305800</td>\n",
              "      <td>0.901961</td>\n",
              "      <td>0.879547</td>\n",
              "      <td>0.865970</td>\n",
              "      <td>0.897778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.198600</td>\n",
              "      <td>0.174131</td>\n",
              "      <td>0.948466</td>\n",
              "      <td>0.938287</td>\n",
              "      <td>0.928723</td>\n",
              "      <td>0.949706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.204400</td>\n",
              "      <td>0.304298</td>\n",
              "      <td>0.901961</td>\n",
              "      <td>0.879547</td>\n",
              "      <td>0.865970</td>\n",
              "      <td>0.897778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.204400</td>\n",
              "      <td>0.173901</td>\n",
              "      <td>0.948466</td>\n",
              "      <td>0.938287</td>\n",
              "      <td>0.928723</td>\n",
              "      <td>0.949706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.200800</td>\n",
              "      <td>0.304476</td>\n",
              "      <td>0.901961</td>\n",
              "      <td>0.879547</td>\n",
              "      <td>0.865970</td>\n",
              "      <td>0.897778</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 815\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 204\n",
            "  Batch size = 8\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 815\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 204\n",
            "  Batch size = 8\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 815\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 204\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 815\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 204\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to bert_results/checkpoint-500\n",
            "Configuration saved in bert_results/checkpoint-500/config.json\n",
            "Model weights saved in bert_results/checkpoint-500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 815\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 204\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 815\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 204\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 815\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 204\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 815\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 204\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 815\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 204\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to bert_results/checkpoint-1000\n",
            "Configuration saved in bert_results/checkpoint-1000/config.json\n",
            "Model weights saved in bert_results/checkpoint-1000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 815\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 204\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 815\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 204\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 815\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 204\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 815\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 204\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 815\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 204\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to bert_results/checkpoint-1500\n",
            "Configuration saved in bert_results/checkpoint-1500/config.json\n",
            "Model weights saved in bert_results/checkpoint-1500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 815\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 204\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 815\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 204\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 815\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 204\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 815\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 204\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 815\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 204\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to bert_results/checkpoint-2000\n",
            "Configuration saved in bert_results/checkpoint-2000/config.json\n",
            "Model weights saved in bert_results/checkpoint-2000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 815\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 204\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2040, training_loss=0.45591403269300274, metrics={'train_runtime': 1430.7653, 'train_samples_per_second': 11.393, 'train_steps_per_second': 1.426, 'total_flos': 4288941241958400.0, 'train_loss': 0.45591403269300274, 'epoch': 20.0})"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classify all of the data into personal story/not personal story "
      ],
      "metadata": {
        "id": "FSP2AaFU2aaB"
      },
      "id": "FSP2AaFU2aaB"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "filtered_data_path = \"all_submissions_filtered.csv\"\n",
        "\n",
        "df = pd.read_csv(filtered_data_path, index_col = 0)\n",
        "df = df.fillna('')\n",
        "df_test = pd.DataFrame().assign(text=df['body'])\n",
        "# df['label'] = [0] * 10\n",
        "data = Dataset.from_pandas(df_test, preserve_index=False)\n",
        "data = data.map(tokenize_function)\n",
        "# print(data)\n",
        "# print(test)\n",
        "\n",
        "labels = trainer.predict(data)\n",
        "# print(labels.predictions[0:10])\n",
        "labels = np.argmax(labels.predictions, axis = 1)\n",
        "df['label'] = labels\n",
        "df.to_csv(\"all_submissions_filtered_labels.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157,
          "referenced_widgets": [
            "1b6a5114448a4be88cd93ac4f6e3823e",
            "a809d53d3790447dbfedcf0ca5ef8287",
            "de5d4d85acac4324aff6d98e33aa3c2a",
            "1094ec102977409ab0674e551e4373a5",
            "10759e68bf2146629fe9baa39bcca424",
            "3d9d5cb12c384910943d32291432bac2",
            "b471fccc4db5449ba3517f15f2d4c18f",
            "7ed29ec359ec476ba96e78c5aa44ed24",
            "a61f9ebb478648e694ccbc6fb8b4961a",
            "33db65c42db047f983d3e61159dff1ae",
            "67fc3f21f9f04e7bac279884db8702fb"
          ]
        },
        "id": "gPo592lsN-Tk",
        "outputId": "c44c981d-bab6-4a92-e53e-be165fd3c141"
      },
      "id": "gPo592lsN-Tk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/144000 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b6a5114448a4be88cd93ac4f6e3823e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 144000\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='21432' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [26/26 1:19:32]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XC38DRqvN1x7"
      },
      "id": "XC38DRqvN1x7",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Archetype_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6ebd9dc6ad3348bdba78c7e84ab97691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04eb6c7853e44ed59f3a7cf0201063f4",
              "IPY_MODEL_36db068be79c4dad996f2426dc6b0b98",
              "IPY_MODEL_3b3007d82b3b4846bfdedcdfea4f36c8"
            ],
            "layout": "IPY_MODEL_9b4c13dde804491398b9f5f9fcb5f74f"
          }
        },
        "04eb6c7853e44ed59f3a7cf0201063f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ad348b196be4585a3e5d294dc44117b",
            "placeholder": "​",
            "style": "IPY_MODEL_41578523fd3046ae9021970f96217d17",
            "value": "100%"
          }
        },
        "36db068be79c4dad996f2426dc6b0b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4d61366dfab46e08e923e4d1e8fb0a2",
            "max": 1019,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5784e1993d9e44ef93243101cfbd33e2",
            "value": 1019
          }
        },
        "3b3007d82b3b4846bfdedcdfea4f36c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d21e8ad2781248d59b128c4672233ff0",
            "placeholder": "​",
            "style": "IPY_MODEL_55073ed8c84648b08c99e156cb1bbaf8",
            "value": " 1019/1019 [00:00&lt;00:00, 1298.55ex/s]"
          }
        },
        "9b4c13dde804491398b9f5f9fcb5f74f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ad348b196be4585a3e5d294dc44117b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41578523fd3046ae9021970f96217d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4d61366dfab46e08e923e4d1e8fb0a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5784e1993d9e44ef93243101cfbd33e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d21e8ad2781248d59b128c4672233ff0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55073ed8c84648b08c99e156cb1bbaf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b6a5114448a4be88cd93ac4f6e3823e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a809d53d3790447dbfedcf0ca5ef8287",
              "IPY_MODEL_de5d4d85acac4324aff6d98e33aa3c2a",
              "IPY_MODEL_1094ec102977409ab0674e551e4373a5"
            ],
            "layout": "IPY_MODEL_10759e68bf2146629fe9baa39bcca424"
          }
        },
        "a809d53d3790447dbfedcf0ca5ef8287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d9d5cb12c384910943d32291432bac2",
            "placeholder": "​",
            "style": "IPY_MODEL_b471fccc4db5449ba3517f15f2d4c18f",
            "value": "100%"
          }
        },
        "de5d4d85acac4324aff6d98e33aa3c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ed29ec359ec476ba96e78c5aa44ed24",
            "max": 144000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a61f9ebb478648e694ccbc6fb8b4961a",
            "value": 144000
          }
        },
        "1094ec102977409ab0674e551e4373a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33db65c42db047f983d3e61159dff1ae",
            "placeholder": "​",
            "style": "IPY_MODEL_67fc3f21f9f04e7bac279884db8702fb",
            "value": " 144000/144000 [02:13&lt;00:00, 1198.97ex/s]"
          }
        },
        "10759e68bf2146629fe9baa39bcca424": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d9d5cb12c384910943d32291432bac2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b471fccc4db5449ba3517f15f2d4c18f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ed29ec359ec476ba96e78c5aa44ed24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a61f9ebb478648e694ccbc6fb8b4961a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33db65c42db047f983d3e61159dff1ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67fc3f21f9f04e7bac279884db8702fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}