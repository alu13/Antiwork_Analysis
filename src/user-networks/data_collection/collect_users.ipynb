{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a list of unique users with their activity statistics\n",
    "\n",
    "This notebook scans through all collected user activity files and produces a single csv with user-level statistics:\n",
    " - number of posts\n",
    " - number of comments\n",
    " - total post karma\n",
    " - total comment karma\n",
    " - first and last date\n",
    "\n",
    "The file produced is stored under `/data/users/summaries/user_stats.csv` and is sorted by total activity in descending order. Good in case want to take only x% most active users for downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../data/users/\"\n",
    "files = [f.absolute() for f in Path(path).glob(\"*.csv\")]\n",
    "user_stats = path + 'summaries/local/user_stats.csv'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 0 out of 12\n",
      "Processing file 1 out of 12\n",
      "Processing file 2 out of 12\n",
      "Processing file 3 out of 12\n",
      "Processing file 4 out of 12\n",
      "Processing file 5 out of 12\n",
      "Processing file 6 out of 12\n",
      "Processing file 7 out of 12\n",
      "Processing file 8 out of 12\n",
      "Processing file 9 out of 12\n",
      "Processing file 10 out of 12\n",
      "Processing file 11 out of 12\n"
     ]
    }
   ],
   "source": [
    "cols_to_read = [\"user_name\", \"no_posts\", \"no_comments\", \"post_karma\", \"comment_karma\", \"first_date\", \"last_date\"] #skip the large json columns\n",
    "\n",
    "def get_file(f):\n",
    "    return pl.scan_csv(f).select(cols_to_read).with_columns([\n",
    "        pl.col(\"first_date\").apply(lambda x: int(time.mktime(datetime.date.fromisoformat(x).timetuple()))),\n",
    "        pl.col(\"last_date\").apply(lambda x: int(time.mktime(datetime.date.fromisoformat(x).timetuple())))\n",
    "    ]).collect()\n",
    "\n",
    "\n",
    "#read in the first file to serve as the baseline\n",
    "df = get_file(files[0])\n",
    "\n",
    "#read in all other files and groupby / add up statistics after each file\n",
    "for i,f in enumerate(files[1:]):\n",
    "    print(\"Processing file {} out of {}\".format(i, len(files) - 1))\n",
    "    new_df = get_file(f)\n",
    "    df.vstack(new_df, in_place=True)\n",
    "    df = df.lazy().groupby(\"user_name\").agg([\n",
    "        pl.col(\"no_posts\").sum(),\n",
    "        pl.col(\"no_comments\").sum(),\n",
    "        pl.col(\"post_karma\").sum(),\n",
    "        pl.col(\"comment_karma\").sum(),\n",
    "        pl.col(\"first_date\").min(),\n",
    "        pl.col(\"last_date\").max()\n",
    "    ]).collect()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add an extra column that captures total activity\n",
    "df = df.with_columns([(pl.col(\"no_posts\") + pl.col(\"no_comments\")).alias(\"total_activity\")])    \n",
    "\n",
    "#save to a single CSV\n",
    "df.lazy().sort(\"total_activity\", reverse=True).collect().to_csv(user_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27878 users (51.6%) with at least 2 activities in the dataset\n",
      "19390 users (35.9%) with at least 3 activities in the dataset\n",
      "12230 users (22.6%) with at least 5 activities in the dataset\n",
      "6225 users (11.5%) with at least 10 activities in the dataset\n",
      "2946 users (5.4%) with at least 20 activities in the dataset\n",
      "946 users (1.7%) with at least 50 activities in the dataset\n",
      "351 users (0.6%) with at least 100 activities in the dataset\n"
     ]
    }
   ],
   "source": [
    "#Check basic statistics on user activity levels\n",
    "activity_levels = [2, 3, 5, 10, 20, 50, 100]\n",
    "total_users = df.shape[0]\n",
    "\n",
    "for level in activity_levels:\n",
    "    no_users = df.filter((pl.col(\"total_activity\") >= level)).shape[0]\n",
    "    print(\"{} users ({:.1f}%) with at least {} activities in the dataset\".format(no_users, no_users / total_users * 100, level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "458e57744219fd35e36fe617bee87769eccb7cd58eff0111259e94f378fae128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
