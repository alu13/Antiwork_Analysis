{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4fa9e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/albertlu/Documents/GitHub/Antiwork_Analysis/src'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "031f52a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_client_id = \"u35-eAIYsZ9aPTx0MY7bcw\"\n",
    "my_client_secret = \"0qUjBGejU5j2xtStKzbK1Y-BUrFywg\"\n",
    "my_user_agent = \"Antiwork_Scrape\"\n",
    "\n",
    "reddit = praw.Reddit(client_id = my_client_id, client_secret = my_client_secret, user_agent = my_user_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48781c67",
   "metadata": {},
   "source": [
    "# PRAW Sanity Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19e14ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekly Discussion Thread\n",
      "PETSMART UNION UPDATE: Management hints at the store closing if the union vote passes. To avoid legal action now they have to post a public statement that it will in fact, not. SUPPORT YOUR LOCAL UNIONS!\n",
      "No one wants to work. Our turnover is terrible.\n"
     ]
    }
   ],
   "source": [
    "new_posts = reddit.subreddit('antiwork').hot(limit = 3)\n",
    "for post in new_posts:\n",
    "    print(post.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2925bf42",
   "metadata": {},
   "source": [
    "# Pytesseract Sanity Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6124dd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Why Gen Zis having a way better starttoth.. % --\n",
      "\n",
      "   \n",
      "\n",
      "(2) Business Insider @ @Businessinsider\n",
      "\n",
      "February 4, 2022\n",
      "\n",
      "Why Gen Z is having a way better start to their\n",
      "adult lives than millennials did\n",
      "\n",
      "In May 2009, along with millions of fellow millennials, Insider senior correspondent\n",
      "Aki Ito graduated from college into what was shaping up to be the worst job market\n",
      "since World War II. So in 2020, when the coronavirus pandemic shuttered vast\n",
      "portions of the economy, there were worries that another lost generation was in the\n",
      "making. But this time, things played out very differently for Gen Z.\n",
      "\n",
      "Photo via @BusinessInsider\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract as py\n",
    "import cv2\n",
    "\n",
    "py.pytesseract.tesseract_cmd = r'/opt/homebrew/Cellar/tesseract/5.0.1/bin/tesseract'\n",
    "img = cv2.imread(r'Tesseract_test.png')\n",
    "print(py.image_to_string(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce8eeee",
   "metadata": {},
   "source": [
    "# Main Scraping Loop\n",
    "\n",
    "This loop scrapes the antiwork subreddit and pulls post/comment/user features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f10f6423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from urllib.request import urlopen\n",
    "\n",
    "image_regex = re.compile(r'https://i.redd.it/')\n",
    "\n",
    "posts = []\n",
    "\n",
    "for post in antiwork.hot(limit = 10):\n",
    "    real_body = post.selftext\n",
    "    if image_regex.search(post.url) != None:\n",
    "        req = urlopen(post.url)\n",
    "        arr = np.asarray(bytearray(req.read()), dtype=np.uint8)\n",
    "        img = cv2.imdecode(arr, -1)\n",
    "        real_body = str(py.image_to_string(img))\n",
    "    addition = [post.title, post.score, post.id, post.subreddit, post.url, post.num_comments, real_body, post.created]\n",
    "    posts.append(addition)\n",
    "\n",
    "posts = pd.DataFrame(posts, columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b27345",
   "metadata": {},
   "source": [
    "# Save the Dataframe as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8ed2bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts.to_csv(\"Scraper_Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98eec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "cmts = set()\n",
    "sub = r.subreddit(\"the_sub\")\n",
    "while True:\n",
    "    try:\n",
    "        cmts.add([c for c in sub.comments(limit=100)])\n",
    "    except KeyboardInterrupt:\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        sleep(30)\n",
    "    sleep(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17168154",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SubredditHelper.__call__() got an unexpected keyword argument 'created'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#     pprint.pprint(vars(post))\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m----> 4\u001b[0m new_posts \u001b[38;5;241m=\u001b[39m \u001b[43mreddit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubreddit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mantiwork\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreated\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m10\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnew(limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m)\n\u001b[1;32m      5\u001b[0m counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m post \u001b[38;5;129;01min\u001b[39;00m new_posts:\n",
      "\u001b[0;31mTypeError\u001b[0m: SubredditHelper.__call__() got an unexpected keyword argument 'created'"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "#     pprint.pprint(vars(post))\n",
    "from datetime import datetime\n",
    "new_posts = reddit.subreddit('antiwork', created = '10').new(limit = 500)\n",
    "counter = 0\n",
    "for post in new_posts:\n",
    "    if counter > 480:\n",
    "        timestamp = post.created_utc\n",
    "        print(datetime.utcfromtimestamp(timestamp))\n",
    "    counter += 1\n",
    "    print(counter)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1558a1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d761fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
