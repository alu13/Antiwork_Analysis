{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a list of unique users with their activity statistics\n",
    "\n",
    "This notebook scans through all collected user activity files and produces a single csv with user-level statistics:\n",
    " - number of posts\n",
    " - number of comments\n",
    " - total post karma\n",
    " - total comment karma\n",
    " - first and last date\n",
    "\n",
    "+ MODIFICATION - only consider posts before 2022 January 10 (timestamp < 1641790800)\n",
    "\n",
    "The file produced is stored under `/data/users/summaries/[machine]/user_stats-cutoff.csv` and is sorted by total activity in descending order. Good in case want to take only x% most active users for downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import time\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "path = \"../../data/users/\"\n",
    "files = [f.absolute() for f in Path(path).glob(\"*.csv\")]\n",
    "print(len(files))\n",
    "user_stats = path + 'summaries/vm2/user_stats-cutoff.csv'\n",
    "max_batch_id = 9979\n",
    "\n",
    "r = re.compile(\"user_interactions-batch-20-(\\d+).csv\")\n",
    "files = [f for f in files if int(r.findall(str(f))[0]) <= max_batch_id]\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 0 out of 120\n",
      "Processing file 1 out of 120\n",
      "Processing file 2 out of 120\n",
      "Processing file 3 out of 120\n",
      "Processing file 4 out of 120\n",
      "Processing file 5 out of 120\n",
      "Processing file 6 out of 120\n",
      "Processing file 7 out of 120\n",
      "Processing file 8 out of 120\n",
      "Processing file 9 out of 120\n",
      "Processing file 10 out of 120\n",
      "Processing file 11 out of 120\n",
      "Processing file 12 out of 120\n",
      "Processing file 13 out of 120\n",
      "Processing file 14 out of 120\n",
      "Processing file 15 out of 120\n",
      "Processing file 16 out of 120\n",
      "Processing file 17 out of 120\n",
      "Processing file 18 out of 120\n",
      "Processing file 19 out of 120\n",
      "Processing file 20 out of 120\n",
      "Processing file 21 out of 120\n",
      "Processing file 22 out of 120\n",
      "Processing file 23 out of 120\n",
      "Processing file 24 out of 120\n",
      "Processing file 25 out of 120\n",
      "Processing file 26 out of 120\n",
      "Processing file 27 out of 120\n",
      "Processing file 28 out of 120\n",
      "Processing file 29 out of 120\n",
      "Processing file 30 out of 120\n",
      "Processing file 31 out of 120\n",
      "Processing file 32 out of 120\n",
      "Processing file 33 out of 120\n",
      "Processing file 34 out of 120\n",
      "Processing file 35 out of 120\n",
      "Processing file 36 out of 120\n",
      "Processing file 37 out of 120\n",
      "Processing file 38 out of 120\n",
      "Processing file 39 out of 120\n",
      "Processing file 40 out of 120\n",
      "Processing file 41 out of 120\n",
      "Processing file 42 out of 120\n",
      "Processing file 43 out of 120\n",
      "Processing file 44 out of 120\n",
      "Processing file 45 out of 120\n",
      "Processing file 46 out of 120\n",
      "Processing file 47 out of 120\n",
      "Processing file 48 out of 120\n",
      "Processing file 49 out of 120\n",
      "Processing file 50 out of 120\n",
      "Processing file 51 out of 120\n",
      "Processing file 52 out of 120\n",
      "Processing file 53 out of 120\n",
      "Processing file 54 out of 120\n",
      "Processing file 55 out of 120\n",
      "Processing file 56 out of 120\n",
      "Processing file 57 out of 120\n",
      "Processing file 58 out of 120\n",
      "Processing file 59 out of 120\n",
      "Processing file 60 out of 120\n",
      "Processing file 61 out of 120\n",
      "Processing file 62 out of 120\n",
      "Processing file 63 out of 120\n",
      "Processing file 64 out of 120\n",
      "Processing file 65 out of 120\n",
      "Processing file 66 out of 120\n",
      "Processing file 67 out of 120\n",
      "Processing file 68 out of 120\n",
      "Processing file 69 out of 120\n",
      "Processing file 70 out of 120\n",
      "Processing file 71 out of 120\n",
      "Processing file 72 out of 120\n",
      "Processing file 73 out of 120\n",
      "Processing file 74 out of 120\n",
      "Processing file 75 out of 120\n",
      "Processing file 76 out of 120\n",
      "Processing file 77 out of 120\n",
      "Processing file 78 out of 120\n",
      "Processing file 79 out of 120\n",
      "Processing file 80 out of 120\n",
      "Processing file 81 out of 120\n",
      "Processing file 82 out of 120\n",
      "Processing file 83 out of 120\n",
      "Processing file 84 out of 120\n",
      "Processing file 85 out of 120\n",
      "Processing file 86 out of 120\n",
      "Processing file 87 out of 120\n",
      "Processing file 88 out of 120\n",
      "Processing file 89 out of 120\n",
      "Processing file 90 out of 120\n",
      "Processing file 91 out of 120\n",
      "Processing file 92 out of 120\n",
      "Processing file 93 out of 120\n",
      "Processing file 94 out of 120\n",
      "Processing file 95 out of 120\n",
      "Processing file 96 out of 120\n",
      "Processing file 97 out of 120\n",
      "Processing file 98 out of 120\n",
      "Processing file 99 out of 120\n",
      "Processing file 100 out of 120\n",
      "Processing file 101 out of 120\n",
      "Processing file 102 out of 120\n",
      "Processing file 103 out of 120\n",
      "Processing file 104 out of 120\n",
      "Processing file 105 out of 120\n",
      "Processing file 106 out of 120\n",
      "Processing file 107 out of 120\n",
      "Processing file 108 out of 120\n",
      "Processing file 109 out of 120\n",
      "Processing file 110 out of 120\n",
      "Processing file 111 out of 120\n",
      "Processing file 112 out of 120\n",
      "Processing file 113 out of 120\n",
      "Processing file 114 out of 120\n",
      "Processing file 115 out of 120\n",
      "Processing file 116 out of 120\n",
      "Processing file 117 out of 120\n",
      "Processing file 118 out of 120\n",
      "Processing file 119 out of 120\n"
     ]
    }
   ],
   "source": [
    "cols_to_read = [\"user_name\", \"no_posts\", \"no_comments\", \"post_karma\", \"comment_karma\", \"first_date\", \"last_date\"] #skip the large json columns\n",
    "\n",
    "def get_file(f):\n",
    "    return pl.scan_csv(f).select(cols_to_read).with_columns([\n",
    "        pl.col(\"first_date\").apply(lambda x: int(time.mktime(datetime.date.fromisoformat(x).timetuple()))),\n",
    "        pl.col(\"last_date\").apply(lambda x: int(time.mktime(datetime.date.fromisoformat(x).timetuple())))\n",
    "    ]).collect()\n",
    "\n",
    "\n",
    "#read in the first file to serve as the baseline\n",
    "df = get_file(files[0])\n",
    "\n",
    "#read in all other files and groupby / add up statistics after each file\n",
    "for i,f in enumerate(files[1:]):\n",
    "    print(\"Processing file {} out of {}\".format(i, len(files) - 1))\n",
    "    new_df = get_file(f)\n",
    "    df.vstack(new_df, in_place=True)\n",
    "    df = df.lazy().groupby(\"user_name\").agg([\n",
    "        pl.col(\"no_posts\").sum(),\n",
    "        pl.col(\"no_comments\").sum(),\n",
    "        pl.col(\"post_karma\").sum(),\n",
    "        pl.col(\"comment_karma\").sum(),\n",
    "        pl.col(\"first_date\").min(),\n",
    "        pl.col(\"last_date\").max()\n",
    "    ]).collect()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add an extra column that captures total activity\n",
    "df = df.with_columns([(pl.col(\"no_posts\") + pl.col(\"no_comments\")).alias(\"total_activity\")])    \n",
    "\n",
    "#save to a single CSV\n",
    "df.lazy().sort(\"total_activity\", reverse=True).collect().to_csv(user_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155805 users (48.8%) with at least 2 activities in the dataset\n",
      "104013 users (32.6%) with at least 3 activities in the dataset\n",
      "61444 users (19.2%) with at least 5 activities in the dataset\n",
      "28172 users (8.8%) with at least 10 activities in the dataset\n",
      "11441 users (3.6%) with at least 20 activities in the dataset\n",
      "2803 users (0.9%) with at least 50 activities in the dataset\n",
      "810 users (0.3%) with at least 100 activities in the dataset\n"
     ]
    }
   ],
   "source": [
    "#Check basic statistics on user activity levels\n",
    "activity_levels = [2, 3, 5, 10, 20, 50, 100]\n",
    "total_users = df.shape[0]\n",
    "\n",
    "for level in activity_levels:\n",
    "    no_users = df.filter((pl.col(\"total_activity\") >= level)).shape[0]\n",
    "    print(\"{} users ({:.1f}%) with at least {} activities in the dataset\".format(no_users, no_users / total_users * 100, level))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "458e57744219fd35e36fe617bee87769eccb7cd58eff0111259e94f378fae128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
