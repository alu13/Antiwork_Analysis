{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0e583a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "# path = '../../data/labeled_data/Clean_Post_Data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b43fef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_id_row(path):\n",
    "    submissions = pd.read_csv(path)\n",
    "    ids = []\n",
    "    for index, row in submissions.iterrows():\n",
    "        k = row['link'].split('/')\n",
    "        ids.append(k[6])\n",
    "    submissions.insert(0, \"id\", ids, True)\n",
    "    submissions.to_csv('Clean_Post_Data.csv')\n",
    "    print(submissions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "968ad936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fx/3y2gshcx7fx5yyrrdm76t3lm0000gn/T/ipykernel_13970/2944042587.py:9: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  df = add_raw_features(clean_data_path, all_submissions_path)\n"
     ]
    }
   ],
   "source": [
    "clean_data_path = '../../data/labeled_data/Clean_Post_Data.csv'\n",
    "all_submissions_path = '../../data/submissions/raw/all_submissions.csv'\n",
    "\n",
    "def add_raw_features(clean_data_path, raw_data_path):\n",
    "    clean = pd.read_csv(clean_data_path)\n",
    "    raw = pd.read_csv(raw_data_path)\n",
    "    merged = pd.merge(clean, raw, left_on=\"id\", right_on=\"id\", how=\"left\")\n",
    "    return merged\n",
    "df = add_raw_features(clean_data_path, all_submissions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7581086a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1184\n",
      "2\n",
      "16052\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [71]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     sentiment_pipeline(data)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#     3. sentiment of the text\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#     4. Toxicity of the text\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#     5. url of the text\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[43madd_extra_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [71]\u001b[0m, in \u001b[0;36madd_extra_features\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin())\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax())\n\u001b[0;32m---> 16\u001b[0m sentiment_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentiment-analysis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI love you\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI hate you\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     18\u001b[0m sentiment_pipeline(data)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Antiwork/lib/python3.10/site-packages/transformers/pipelines/__init__.py:549\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;66;03m# Infer the framework from the model\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;66;03m# Forced if framework already defined, inferred if it's None\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m# Will load the correct model if possible\u001b[39;00m\n\u001b[1;32m    548\u001b[0m model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m--> 549\u001b[0m framework, model \u001b[38;5;241m=\u001b[39m \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    561\u001b[0m load_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(model_config) \u001b[38;5;129;01min\u001b[39;00m TOKENIZER_MAPPING \u001b[38;5;129;01mor\u001b[39;00m model_config\u001b[38;5;241m.\u001b[39mtokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Antiwork/lib/python3.10/site-packages/transformers/pipelines/base.py:199\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03mSelect framework (TensorFlow or PyTorch) to use from the `model` passed. Returns a tuple (framework, model).\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m    `Tuple`: A tuple framework, model.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available():\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one of TensorFlow 2.0 or PyTorch should be installed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install PyTorch, read the instructions at https://pytorch.org/.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m     )\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    205\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task\n",
      "\u001b[0;31mRuntimeError\u001b[0m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/."
     ]
    }
   ],
   "source": [
    "def count_unique_words(data):\n",
    "    data = data.split(' ')\n",
    "    count = len(set(data))\n",
    "    return count\n",
    "def add_extra_features(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if type(row['body']) != str:\n",
    "            row['body'] = str(row['body'])\n",
    "    df['body'] = df['body'].map(lambda body: str(body))\n",
    "    df['length'] = df['body'].map(lambda body: len(body))\n",
    "    df['count'] = df['body'].map(lambda body: count_unique_words(body))\n",
    "    print(df['count'].min())\n",
    "    print(df['count'].max())\n",
    "    print(df['length'].min())\n",
    "    print(df['length'].max())\n",
    "    sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "    data = [\"I love you\", \"I hate you\"]\n",
    "    sentiment_pipeline(data)\n",
    "#     3. sentiment of the text\n",
    "#     4. Toxicity of the text\n",
    "#     5. url of the text\n",
    "add_extra_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c19ae5b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'detoxify'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetoxify\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Detoxify\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# each model takes in either a string or a list of strings\u001b[39;00m\n\u001b[1;32m      5\u001b[0m results \u001b[38;5;241m=\u001b[39m Detoxify(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexample text\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'detoxify'"
     ]
    }
   ],
   "source": [
    "from detoxify import Detoxify\n",
    "\n",
    "# each model takes in either a string or a list of strings\n",
    "\n",
    "results = Detoxify('original').predict('example text')\n",
    "\n",
    "# optional to display results nicely (will need to pip install pandas)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print(pd.DataFrame(results, index=input_text).round(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acf67e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
